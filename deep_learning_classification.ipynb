{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dados/cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Score', 'Gender', 'Age', 'Assets', 'Products', 'Active']]\n",
    "y = df['Churned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1).to(device)  # Reshape y for compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = train_test_split(X_tensor, y_tensor, test_size=0.1, random_state=42)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network model\n",
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
    "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
    "        self.fc3 = nn.Linear(hidden2_size, 1)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gelu(self.fc1(x))\n",
    "        x = self.gelu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate the model using cross-validation\n",
    "\n",
    "def cross_val_model(hidden1_size, hidden2_size, learning_rate):\n",
    "    hidden1_size = int(hidden1_size)\n",
    "    hidden2_size = int(hidden2_size)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_accuracies = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_tensor):\n",
    "        X_train_fold = X_tensor[train_index]\n",
    "        y_train_fold = y_tensor[train_index]\n",
    "        X_val_fold = X_tensor[val_index]\n",
    "        y_val_fold = y_tensor[val_index]\n",
    "\n",
    "        # create DataLoader for training fold\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=9, shuffle=True)\n",
    "\n",
    "        # Initialize the model, criterion, and optmizer\n",
    "        model = BinaryClassificationModel(X_train_fold.shape[1], hidden1_size, hidden2_size).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for epoch in range(50):\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the validation fold\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_probs = model(X_val_fold)\n",
    "            y_pred = (y_pred_probs > 0.5).float()\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        acc = accuracy_score(y_val_fold.cpu().numpy(), y_pred.cpu().numpy())\n",
    "        cv_accuracies.append(acc)\n",
    "\n",
    "    # Return the average accuracy across folds\n",
    "    return np.mean(cv_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameter bounds for Bayesian Optimization\n",
    "param_bounds = {\n",
    "    'hidden1_size': (32, 128),  # Number of neurons in the first hidden layer\n",
    "    'hidden2_size': (16, 64),   # Number of neurons in the second hidden layer\n",
    "    'learning_rate': (0.0001, 0.01)  # Learning rate for training\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | hidden... | hidden... | learni... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.4412   \u001b[39m | \u001b[39m67.96    \u001b[39m | \u001b[39m61.63    \u001b[39m | \u001b[39m0.007347 \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.7958   \u001b[39m | \u001b[35m89.47    \u001b[39m | \u001b[35m23.49    \u001b[39m | \u001b[35m0.001644 \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.6798   \u001b[39m | \u001b[39m37.58    \u001b[39m | \u001b[39m57.58    \u001b[39m | \u001b[39m0.006051 \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.5692   \u001b[39m | \u001b[39m99.97    \u001b[39m | \u001b[39m16.99    \u001b[39m | \u001b[39m0.009702 \u001b[39m |\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m0.7968   \u001b[39m | \u001b[35m111.9    \u001b[39m | \u001b[35m26.19    \u001b[39m | \u001b[35m0.0019   \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.5492   \u001b[39m | \u001b[39m111.8    \u001b[39m | \u001b[39m26.15    \u001b[39m | \u001b[39m0.006438 \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7838   \u001b[39m | \u001b[39m47.44    \u001b[39m | \u001b[39m35.15    \u001b[39m | \u001b[39m0.0009565\u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.6768   \u001b[39m | \u001b[39m63.22    \u001b[39m | \u001b[39m39.0     \u001b[39m | \u001b[39m0.001514 \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.5552   \u001b[39m | \u001b[39m122.5    \u001b[39m | \u001b[39m33.66    \u001b[39m | \u001b[39m0.002291 \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.3252   \u001b[39m | \u001b[39m117.8    \u001b[39m | \u001b[39m57.35    \u001b[39m | \u001b[39m0.004191 \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.6948   \u001b[39m | \u001b[39m63.9     \u001b[39m | \u001b[39m48.64    \u001b[39m | \u001b[39m0.009634 \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.5552   \u001b[39m | \u001b[39m41.07    \u001b[39m | \u001b[39m54.46    \u001b[39m | \u001b[39m0.005997 \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.5432   \u001b[39m | \u001b[39m70.69    \u001b[39m | \u001b[39m56.35    \u001b[39m | \u001b[39m0.0076   \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.4448   \u001b[39m | \u001b[39m90.59    \u001b[39m | \u001b[39m26.63    \u001b[39m | \u001b[39m0.009764 \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.4508   \u001b[39m | \u001b[39m35.92    \u001b[39m | \u001b[39m39.47    \u001b[39m | \u001b[39m0.005957 \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7948   \u001b[39m | \u001b[39m61.6     \u001b[39m | \u001b[39m57.33    \u001b[39m | \u001b[39m0.001029 \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.3052   \u001b[39m | \u001b[39m111.7    \u001b[39m | \u001b[39m46.69    \u001b[39m | \u001b[39m0.004631 \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.6718   \u001b[39m | \u001b[39m57.75    \u001b[39m | \u001b[39m28.25    \u001b[39m | \u001b[39m0.005094 \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.5728   \u001b[39m | \u001b[39m90.79    \u001b[39m | \u001b[39m18.95    \u001b[39m | \u001b[39m0.004306 \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.7888   \u001b[39m | \u001b[39m88.87    \u001b[39m | \u001b[39m50.54    \u001b[39m | \u001b[39m0.001367 \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.3192   \u001b[39m | \u001b[39m122.8    \u001b[39m | \u001b[39m37.67    \u001b[39m | \u001b[39m0.009112 \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.7938   \u001b[39m | \u001b[39m97.34    \u001b[39m | \u001b[39m32.98    \u001b[39m | \u001b[39m0.001527 \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.5468   \u001b[39m | \u001b[39m64.29    \u001b[39m | \u001b[39m18.79    \u001b[39m | \u001b[39m0.008797 \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.4412   \u001b[39m | \u001b[39m116.5    \u001b[39m | \u001b[39m56.21    \u001b[39m | \u001b[39m0.003276 \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.4412   \u001b[39m | \u001b[39m63.59    \u001b[39m | \u001b[39m62.23    \u001b[39m | \u001b[39m0.005102 \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.6688   \u001b[39m | \u001b[39m105.8    \u001b[39m | \u001b[39m19.92    \u001b[39m | \u001b[39m0.00642  \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.5492   \u001b[39m | \u001b[39m82.57    \u001b[39m | \u001b[39m26.62    \u001b[39m | \u001b[39m0.009365 \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.3192   \u001b[39m | \u001b[39m38.75    \u001b[39m | \u001b[39m53.47    \u001b[39m | \u001b[39m0.008738 \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.6692   \u001b[39m | \u001b[39m50.38    \u001b[39m | \u001b[39m36.19    \u001b[39m | \u001b[39m0.008847 \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m0.5528   \u001b[39m | \u001b[39m91.23    \u001b[39m | \u001b[39m18.26    \u001b[39m | \u001b[39m0.00846  \u001b[39m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run Bayesian Optimization\n",
    "optimizer = BayesianOptimization(f=cross_val_model, pbounds=param_bounds, random_state=42)\n",
    "optimizer.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found:\n",
      "{'target': 0.7968140703517588, 'params': {'hidden1_size': 111.91449351684048, 'hidden2_size': 26.192277312557255, 'learning_rate': 0.0019000671753502962}}\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(\"Best Parameters Found:\")\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best parameters found and evaluate it\n",
    "best_params = optimizer.max['params']\n",
    "model = BinaryClassificationModel(X_tensor.shape[1], int(best_params['hidden1_size']), int(best_params['hidden2_size'])).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for training the final model\n",
    "train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the full dataset\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the final model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_probs = model(X_test_tensor.to(device))\n",
    "    y_pred = (y_pred_probs > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the final model\n",
    "accuracy = accuracy_score(y_test_tensor.cpu().numpy(), y_pred.cpu().numpy())\n",
    "print(\"\\nTest Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "             Non_churned(pred)  Churned(pred)\n",
      "Non-Churned                 75              4\n",
      "Churned                     19              2\n"
     ]
    }
   ],
   "source": [
    "# Compute and format the confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_tensor.cpu().numpy(), y_pred.cpu().numpy())\n",
    "cnf_table = pd.DataFrame(data=cnf_matrix, index=['Non-Churned', 'Churned'], columns=['Non_churned(pred)', 'Churned(pred)'])\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cnf_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non Churned       0.80      0.95      0.87        79\n",
      "     Churned       0.33      0.10      0.15        21\n",
      "\n",
      "    accuracy                           0.77       100\n",
      "   macro avg       0.57      0.52      0.51       100\n",
      "weighted avg       0.70      0.77      0.72       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report with target names\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_tensor.cpu().numpy(), y_pred.cpu().numpy(), target_names=['Non Churned', 'Churned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
